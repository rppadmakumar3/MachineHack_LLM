{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "20a58a6e-9091-4f9c-979a-34715eed0d92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "421816be78ec4687af25adf582a1f3b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89322d9e-ce6f-4aae-a850-dd3c6ed893bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# dataset = load_dataset('')['train'].train_test_split(test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da029a92-fd75-411e-a75b-08cc54337451",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Story': \"CHAPTER XXIV \\n\\nEnid, my early and my only love, I thought, but that your father came between, In former days you saw me favourably, And if it were so, do not keep it back, Make me a little happier, let me know it.--TENNYSON \\n\\nThe foreign tour proved a great success. The summer in the Alps was delightful. The complete change gave Bertha new life, bodily strength first returning, and then mental activity. The glacier system was a happy exchange for her _ego_, and she observed and enjoyed with all the force of her acute intelligence and spirit of inquiry, while Phoebe was happy in doing her duty by profiting by all opportunities of observation, in taking care of Maria and listening to Mervyn, and Miss Charlecote enjoyed scenery, poetry, art, and natural objects with relish keener than even that of her young friends, who were less impressible to beauty in every shape. \\n\\nMervyn behaved very well to her, knowing himself bound to make the journey agreeable to her; he was constantly kind to Bertha, and in the pleasure of her revival submitted to a wonderful amount of history and science. All his grumbling was reserved for the private ear of Phoebe, whose privilege it always was to be his murmuring block, and who was only too thankful to keep to herself his discontents whenever his route was not chosen (and often when it was), his disgusts with inns, railroads, and sights and his impatience of all pursuits save Bertha's. Many a time she was permitted to see and hear nothing but how much he was bored, but on the whole the growls were so mitigated compared with what she had known, that it was almost contentment; and that he did not absolutely dislike their habits was plain from his adherence to the ladies, though he might have been quite independent of them. \",\n",
       " 'Question': 'Was he supposedly in dependent of the ladies?',\n",
       " 'span_start': 1597.0,\n",
       " 'span_end': 1777.0,\n",
       " 'span_text': 'that it was almost contentment; and that he did not absolutely dislike their habits was plain from his adherence to the ladies, though he might have been quite independent of them.',\n",
       " 'Answer': \"He could have been but he wasn't\"}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5746584b-d365-49a0-925f-266a0b97d92a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-cased-distilled-squad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be42fdfa-ef2d-47ae-8a97-fd06e08e31b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "    stories = [story.strip() for story in examples[\"Story\"]]\n",
    "    questions = [question.strip() for question in examples[\"Question\"]]\n",
    "    span_starts = examples[\"span_start\"]\n",
    "    span_ends = examples[\"span_end\"]\n",
    "    answers = [answer.strip() for answer in examples[\"Answer\"]]\n",
    "\n",
    "    inputs = tokenizer(\n",
    "        questions,\n",
    "        stories,\n",
    "        max_length=512,\n",
    "        truncation=\"only_second\",\n",
    "        padding=\"max_length\",\n",
    "        return_offsets_mapping=True,\n",
    "    )\n",
    "\n",
    "    offset_mapping = inputs.pop(\"offset_mapping\")\n",
    "    start_positions = []\n",
    "    end_positions = []\n",
    "    extracted_answers = []\n",
    "\n",
    "    for i, offset in enumerate(offset_mapping):\n",
    "        span_start = span_starts[i]\n",
    "        span_end = span_ends[i]\n",
    "        answer = answers[i]\n",
    "\n",
    "        # Find the start and end of the context\n",
    "        context_start = next((idx for idx, (start, end) in enumerate(offset) if start == 0), None)\n",
    "        context_end = next((idx for idx, (start, end) in enumerate(offset) if end == 0), None)\n",
    "\n",
    "        if span_start is not None and span_end is not None and context_start is not None and context_end is not None:\n",
    "            # If the answer is fully inside the context, label it (0, 0)\n",
    "            if span_start < offset[context_start][0] or span_end > offset[context_end][1]:\n",
    "                start_positions.append(0)\n",
    "                end_positions.append(0)\n",
    "                extracted_answers.append(\"\")  # Store an empty string for evaluation\n",
    "            else:\n",
    "                # Otherwise, it's the start and end token positions\n",
    "                while context_start < len(offset) and offset[context_start][0] != 0:\n",
    "                    context_start += 1\n",
    "\n",
    "                start_positions.append(context_start)\n",
    "\n",
    "                context_end -= 1  # Adjust for the padding token\n",
    "                while context_end >= 0 and offset[context_end][1] != 0:\n",
    "                    context_end -= 1\n",
    "\n",
    "                end_positions.append(context_end)\n",
    "\n",
    "                # Extract the answer text from the 'Story' using the positions\n",
    "                extracted_answer = stories[i][offset[start_positions[-1]][0]:offset[end_positions[-1]][1]].strip()\n",
    "                extracted_answers.append(extracted_answer)\n",
    "        else:\n",
    "            # If span_start, span_end, context_start, or context_end is None, mark as (0, 0)\n",
    "            start_positions.append(0)\n",
    "            end_positions.append(0)\n",
    "            extracted_answers.append(\"\")\n",
    "\n",
    "    inputs[\"start_positions\"] = start_positions\n",
    "    inputs[\"end_positions\"] = end_positions\n",
    "    inputs[\"extracted_answers\"] = extracted_answers\n",
    "\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7b1bf8ca-b0fc-4150-ab65-6910f3c6e3d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31e3787eb1ea4c02b4ce7067f9672dfd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/53288 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0eb3cf5e33ec491bb7ea71bb2d2f9b71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/13323 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_dataset = dataset.map(preprocess_function, batched=True, remove_columns=dataset[\"train\"].column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "70850359-2ad7-4a6e-af32-21acc29a157c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DefaultDataCollator\n",
    "\n",
    "data_collator = DefaultDataCollator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "45071520-783b-4a73-9f7f-a1d4a9f10cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForQuestionAnswering, TrainingArguments, Trainer\n",
    "\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(\"distilbert-base-cased-distilled-squad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "145deea3-6fbe-4cfe-a852-1a8a7f9309a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/common/miniconda3/envs/pytorch_xpu/lib/python3.10/site-packages/intel_extension_for_pytorch/frontend.py:522: UserWarning: Conv BatchNorm folding failed during the optimize process.\n",
      "  warnings.warn(\"Conv BatchNorm folding failed during the optimize process.\")\n",
      "/home/common/miniconda3/envs/pytorch_xpu/lib/python3.10/site-packages/intel_extension_for_pytorch/frontend.py:527: UserWarning: Linear BatchNorm folding failed during the optimize process.\n",
      "  warnings.warn(\"Linear BatchNorm folding failed during the optimize process.\")\n"
     ]
    }
   ],
   "source": [
    "import intel_extension_for_pytorch as ipex\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "model, optimizer = ipex.optimize(model, optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a50e20-5569-4060-8196-d4371ade8855",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"qa_finetuned_model\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=55,\n",
    "    per_device_eval_batch_size=55,\n",
    "    num_train_epochs=1,\n",
    "    weight_decay=0.01,\n",
    "    push_to_hub=True,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0460fe92-b623-4c9b-8968-985e489b1a6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating 10/10\n",
      "Accuracy on the test dataset: 20.00%\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForQuestionAnswering\n",
    "from datasets import load_dataset\n",
    "import intel_extension_for_pytorch as ipex\n",
    "import torch\n",
    "\n",
    "# # Load your custom dataset\n",
    "# dataset = load_dataset(\"DATASET\")\n",
    "# dataset = load_dataset('DATASET')['train'].train_test_split(train_size=10, test_size=10)\n",
    "\n",
    "# Access the test split of your dataset\n",
    "eval_dataset = dataset[\"test\"]\n",
    "\n",
    "# Load the tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-cased-distilled-squad\")\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(\"distilbert-base-cased-distilled-squad\")\n",
    "\n",
    "model = ipex.optimize(model)\n",
    "\n",
    "# Initialize variables to keep track of correct and total predictions\n",
    "correct_predictions = 0\n",
    "total_predictions = 0\n",
    "\n",
    "# Iterate through the evaluation dataset\n",
    "for idx, example in enumerate(eval_dataset):\n",
    "    question = example[\"Question\"]\n",
    "    context = example[\"Story\"]\n",
    "    answer = example[\"Answer\"]\n",
    "\n",
    "    # Tokenize the input text\n",
    "    inputs = tokenizer.encode_plus(question, context, return_tensors=\"pt\")\n",
    "\n",
    "    # Use the model to predict the answer\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "    # Extract the predicted answer\n",
    "    start_logits, end_logits = outputs.start_logits, outputs.end_logits\n",
    "    start_index = torch.argmax(start_logits)\n",
    "    end_index = torch.argmax(end_logits)\n",
    "    predicted_answer = tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"][0][start_index:end_index+1]))\n",
    "\n",
    "    # Check if the predicted answer matches the ground truth answer\n",
    "    if predicted_answer == answer:\n",
    "        correct_predictions += 1\n",
    "\n",
    "    total_predictions += 1\n",
    "\n",
    "    # Print the progress indicator\n",
    "    print(f\"Evaluating {idx + 1}/{len(eval_dataset)}\", end=\"\\r\")\n",
    "\n",
    "# Calculate the accuracy\n",
    "accuracy = correct_predictions / total_predictions\n",
    "\n",
    "# Print the final accuracy\n",
    "print(f\"\\nAccuracy on the test dataset: {accuracy * 100:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
